---
format: rst
title: LLVM on AOSABOOK
...

 이 챕터는 LLVM 을 만들어온 디자인 결정사항들에 대해 이야기한다. LLVM은 어셈블러, 컴파일러, 디버거 등의 저수준 툴체인 셋을 아우르는 프로젝트이다. 기존 유닉스 시스템에서 쓰이던 툴과 호환되도록 디자인 되었다. "LLVM"은 원래 약자였지만(Low-Level Virtual Machine) 이제는 관련 프로젝트를 총괄하는 프로젝트 브랜드가 되었다. LLVM은 그 자체만의 기능 뿐 아니라 훌륭한 관련 도구들(CLang 같은...)로도 유명하지만, LLVM 을 다른 컴파일러들과 구분해주는 가장 큰 특징은 그 아키텍쳐에 있다.

 2000년 12월에 처음 프로젝트가 시작되었을 때 부터, LLVM은 잘 정의된 인터페이스를 가진 **재사용 가능한 라이브러리 모음**이 되도록 디자인되었다. 당시에 오픈소스 프로그래밍 언어의 구현들은 보통 하나의 실행파일로 이루어진 특정 용도 전용으로 설계되었다. 예를 들어 정적인 컴파일러로부터 파서를 뽑아내서 정적분석이나 리팩토링을 위해 재사용하는 것은 매우 어려운 일이다. - GCC를 생각해보라! 반면 스크립트 언어들은 보다 큰 프로그램에 런타임/해석기를 내장하는 경우가 많은데, 보통 그 런타임은 하나의 거대한 코드덩어리로 그 일부를 재사용하는 것도 어려울 뿐더러 여러 언어 구현에 공유되는 경우도 거의 없다.

 컴파일러 그 자체의 구성 이외에도, 인기있는 언어 구현체를 사용하는 커뮤니티는 보통 대단히 편중되어 있다. 구현체는 보통 전통적인 컴파일러(GCC, FreePascal같은...)를 제공하거나 혹은 인터프리터나 JIT(Just-In-Time) 컴파일러를 제공한다. 이 양쪽을 모두 지원하는 언어 구현체를 대단히 희귀하고, 있던 경우에도 이 양쪽 구현은 거의 코드를 공유하지 않았다.

 지난 10년간 LLVM은 이런 구도를 상당히 많이 바꾸어 냈다. LLVM은 요즘 정적 컴파일러, 런타임 컴파일러 양쪽 전반에 걸쳐 폭넓게 사용되는 전반 기술이다. 또한, 여러개의 특수화된 전용 컴파일러를 대체하기도 했다. 예를 들면, 애플의 OpenGL 스택이나 어도비 After Effect의 이미지 프로세싱 라이브러리 같은 부분에 사용되었다. 마지막으로 LLVM은 새 제품을 만드는 데에도 많이 사용되는데, 아마 가장 잘 알려진 것은 OpenCL GPU 프로그래밍 언어와 런타임일 것이다.

1. A Quick Introduction to Classical Compiler Design

 전통적인 정적 컴파일러(대부분의 C 컴파일러)의 가장 흔한 설계는 3단계 설계이다. 3단계 설계는 프론트엔드(Frontend), 최적화모듈(Optimizer), 백엔드(Backend)의 3개 컴포넌트로 구성된다.

 .. image:: http://www.aosabook.org/images/llvm/SimpleCompiler.png

 각 컴포넌트는:

Frontend
  소스코드 파싱, 에러검사, 입력 코드를 나타내는 언어마다의 `AST<http://en.wikipedia.org/wiki/Abstract_syntax_tree>`_(Abstract Syntax Tree) 를 생성하는 일을 한다. AST는 최적화를 위해 별도의 형식으로 표현될 수 있다.

Optimizer
  코드의 실행 속도를 향상시키기 위한 여러가지 변환 작업(예: 중복 계산 제거)을 한다. 이런 작업은 보통 언어/타겟 아키텍쳐와 독립적이다.

Backend
  코드 생성기라고도 한다. 코드를 타겟 명령어셋에 맞도록 변환한다. *올바른* 코드를 생성하는 것은 물론이고, 아키텍쳐에서 지원하는 특징을 잘 사용하여 *좋은* 코드를 생성해야 한다. 컴파일러 백엔드는 보통 명령어 선택, 레지스터 할당, 명령 스케쥴링 등을 작업을 한다.

 이 모델은 인터프리터나 JIT 컴파일러에도 똑같이 잘 적용된다. 자바 가상 머신(JVM)도 자바 바이트코드를 프론트엔드와 최적화 사이의 인터페이스로 사용하는 이 모델-3단계 디자인-의 구현체이다.

 - Implications of this Design

  이 클래식한 설계의 가장 중요한 이점은 컴파일러가 여러가지 소스 언어, 혹은 여러개의 타겟 아키텍쳐를 지원하고자 할 때 생긴다. 만약 컴파일러가 최적화 단계에서 하나의 코드 표현을 사용한다면, 프론트엔드는 어떤 언어라도 그 코드 표현으로 컴파일 하기만 하면 되고, 백엔드는 그 코드 표현에 대해서만 만들어지면 된다. 아래 그림을 참고하자.

  .. image:: http://www.aosabook.org/images/llvm/RetargetableCompiler.png

  이 설계에서는, 새로운 소스 언어를 지원하기 위한 작업은 새 프론트엔드의 구현 뿐이다. 기존의 최적화 모듈과 백엔드는 재사용할 수 있기 때문이다. 만약 각 부분들이 분리되어 있지 않다면, 새 소스 언어의 구현은 바닥부터 작업해야 하는 일이 되고, N 개의 타겟과 M 개의 소스 언어를 지원하기 위해서 N*M 개의 컴파일러를 필요로 하게 된다.

  3단계 구현의 또 다른 이점은 (위의 장점과 직접적으로 연관되었다) 여러개의 언어를 지원함으로써 컴파일러가 더 넓은 프로그래머들에게 쓰일 수 있고, 따라서 더 큰 커뮤니티를 형성할 수 있다는 점이다. 더 큰 커뮤니티는 더 많은 기여자를 이끌어내고, 자연스럽게 더 많은 개선이 가능하다. 이게 바로 GCC 같이 많은 커뮤니티에서 쓰이는 컴파일러가 FreePASCAL같이 좁은 범위에서 사용되는 컴파일러보다 최적화가 잘 된 기계어를 생성해내는 이유가 된다. 하지만 상용 컴파일러같은 경우에는 예산이 코드의 질로 바로 연결되기 때문에 경우가 조금 다르다고 할 수 있다. 예를 들어서 ICC 컴파일러는 좁은 사용자층에도 불구하고 훌륭한 코드를 생성해 낸다고 알려져 있다.

  3단계 구현의 마지막 이점은, 각 3개 컴포넌트를 구현하는데 필요한 기술이 다르다는 점이다. 필요 기술을 분리하는 것은 각 컴포넌트를 작업하는 사람이 맡은 부분을 개선하고 유지해나가는 것을 보다 쉽게 만들어준다. 이것이 기술이 아닌 **사회적**인 이슈이긴 하지만 실제적으로 아주 중요하다. 특히나, 이런 오픈소스 프로젝트가 기여를 받기 위한 진입장벽을 낮추는 데에 크게 도움이 된다.

2. Existing Language Implementation

 3단계 디자인의 이점이 명백하고, 관련 교과서 등에 잘 설명되어 있지만 실제적으로 실현된 경우는 거의 없다. LLVM이 시작되었던 시기로부터 뒤돌아 오픈소스 언어 구현체를 살펴보면, Perl, Python, Ruby, Java 등의 구현체가 공유하는 코드가 없다는 것을 알 수 있다. 또한, Glasgow Haskell Compiler(GHC)나 FreeBASIC 같은 언어들은 여러 다른 CPU를 지원하지만 그 구현들은 지원하는 소스 언어에 대단히 의존적이다. 그 외에도 이미지 프로세싱에 쓰이는 JIT 컴파일러, 정규식, 그래픽 카드 드라이버 등 CPU 작업이 주를 이루는 특수 목적의 컴파일러 기술도 많다.

 정리해보면 이 모델의 성공 스토리로 주요한 3개의 예가 있다. 그 **첫번째** 는 자바와 .NET 의 **가상머신**이다.

 **두번째** 성공의 예는 아마도 가장 불운한, 하지만 컴파일러 기술을 재사용하는 가장 인기있는 방법일 것이다. 바로 - **입력 소스 코드를 C 코드로 변환**하여 기존의 C 컴파일러에게 보내는 것이다. 이 방법은, 최적화기, 코드 생성기 등을 재사용할 수 있으며 매우 유연하고, 프론트엔드를 구현하는 사람이 이해하기 쉽고 유지보수도 쉽다. 하지만 이 방법은 효율적인 예외 처리를 방해하며, 디버깅 환경도 매우 좋지 않다. 또한 컴파일 시간도 오래 걸리고 C에서 지원하지 않는 특징을 지원하는 언어에 대해서는 문제의 소지가 있다.

 **마지막** 예는 바로 **GCC** 이다. GCC는 여러 프론트엔드, 백엔드를 지원하며 여러 커뮤니티에 걸쳐 활발하게 활동하는 기여자들을 가지고 있다. GCC 는 여러 타겟을 지원하는 C 컴파일러로 오랜 시간을 보냈고, 당시에는 다른 몇몇 언어를 지원하기 위해 여러 꽁수를 사용했다. 시간이 지나며 GCC 커뮤니티는 점차적으로 보다 깨끗한 설계로 진화했다. GCC 4.4에 이르러서는 최적화기를 위한 새로운 표현 방식(`GIMPLE Tuples<http://gcc.gnu.org/wiki/tuples/>`_)이 생겼는데 전에 비해 프론트엔드와 보다 분리되는 쪽의 변화이다. 또한 GCC의 포트란/ADA 프론트엔드는 깔끔한 AST를 사용한다.

 이런 시도들이 매우 성공적이었지만, 한편 기본적으로 monolithic 방식으로 설계되었기 때문에 이런 접근 방식에 한계가 있을 수밖에 없었다. 한 예로, GCC 를 다른 어플리케이션에 포함시키거나, GCC를 런타임/JIT 컴파일러로 사용하거나, 혹은 컴파일러의 대부분을 가져오지 않고 GCC의 일부만 재사용하는 일은 거의 불가능하다. GCC의 C++ 프론트엔드를 문서 생성기, 코드 인덱싱, 리팩토링, 정적 분석기 등에 사용하고 싶은 사람은 GCC가 생성하는 XML을 사용하기 위해 통짜로 사용하거나, 다른 코드를 GCC 프로세스에 끼워 넣는 플러그인을 만들어야만 한다.

 GCC의 각 조각들이 라이브러리로 사용될 수 없는 이유는 여러 가지가 있다. 전역 변수의 남발, 거의 강제되지 않은 불변값, 잘못 설계된 자료구조, 조각조각 파편화된 코드베이스, 한번에 하나의 프론트엔드/타겟 페어로만 빌드할 수 있는 매크로 사용 등. 하지만 가장 고치기 어려운 문제는, 초기 설계로부터 전해내려오는 구조적인 결함이다. 특히, GCC는 추상화 단계가 잘 갖추어지지 않아 레이어링에 문제를 겪고 있다. 즉, 백엔드에서 디버그 정보를 생성하기 위해 프론트엔드의 AST를 뒤져야 한다거나, 프론트엔드가 백엔드의 자료구조를 생성한다거나, 전체 컴파일러가 커맨드라인에 의해 설정된 전역 자료구조에 크게 의존하는 등의 문제가 있다.

3. LLVM's Code Representation: LLVM IR

 이런 역사적인 배경지식을 가지고 LLVM을 한번 살펴보자. 설계의 가장 중요한 부분은 바로 **LLVM Intermediate Representation(IR)** 이다. LLVM IR은 컴파일러가 코드를 나타내기 위해 사용하는 스펙으로, 중간 단계의 분석 및 최적화 변환에 사용한다. 여러가지 확실한 목적을 염두에 두고 설계되었는데, 그 중에는 가벼운 런타임 최적화, 여러개의 함수/프로시저를 통합한 최적화, 전체 프로그램 분석, 공격적인 재구조화 변환 등이 있다. 핵심은, LLVM IR 자체가 잘 정의된 의미를 가진 언어라는 점이다. 여기 구체적인 예가 있다.::

  define i32 @add1(i32 %a, i32 %b) {
  entry:
    %tmp1 = add i32 %a, %b
    ret i32 %tmp1
  }

  define i32 @add2(i32 %a, i32 %b) {
  entry:
    %tmp1 = icmp eq i32 %a, 0
    br i1 %mp1, label %done, label %recurse

  recurse:
    %tmp2 = sub i32 %a, 1
    %tmp3 = add i32 %b, 1
    %tmp4 = call i32 @add2(i32 %tmp2, i32 %tmp3)
    ret i32 %tmp4

  done:
    ret i32 %b
  }

 위의 LLVM IR로 작성된 두 함수는 각각 아래의 C 코드를 표현하는 것으로, 두 정수를 더하는 서로 다른 방법이다.::

  unsigned add1(unsigned a, unsigned b) {
    return a+b;
  }

  unsigned add2(unsigned a, unsigned b) {
    if (a==0) return b;
    return add2(a-1, b+1);
  }

 위의 예에서 볼 수 있듯 LLVM IR은 저수준의 RISC와 같은 가상 명령어 집합이다. **실제 RISC와 같이** *더하기, 빼기, 비교, 분기* 등의 간단한 명령어들을 지원한다. 이 명령들은 3-주소-형식인데, 이는 명령어가 몇 개의 입력을 받고, 입력이 아닌 다른 레지스터에 결과를 저장한다는 것을 의미한다. LLVM IR은 레이블도 지원하고, 일반적으로는 좀 이상한 형태의 어셈블리 언어처럼 보인다.

 대부분의 RISC 명령어 집합과 다른 점으로는, LLVM IR은 간단한 타입 시스템을 가진 **강 타입** 언어이고, 실제 기계의 상세한 부분을 추상화시켜 버렸다는 부분을 들 수 있다. 예를 들어 *call*, *ret*와 명시적인 인자 전달을 통하여 호출 규약(calling convention)을 추상화시켜 버렸다. 기계어와 또 다른 중요한 차이점은 레지스터의 수이다. LLVM IR 은 임시로 이름을 붙일 수 있는 무한한 수의 레지스터를 가질 수 있따. 임시 이름은 **%**를 앞에 붙임으로써 생성할 수 있다.

 언어로써의 구현 이외에, LLVM IR은 3가지의 서로 동등한 형태로 정의된다. 각각 위에 설명한 *텍스트 형식*, 최적화를 위해 변경되고 조사하기 위한 *메모리 적재 자료구조*, 마지막으로 디스크에 저장하기 위한 압축적인 *bit-code* 형식이다. LLVM 프로젝트는 각 포맷간의 변환을 위한 툴을 제공한다. *llvm-as* 는 텍스트 형식(.ll)을 bit-code(.bc)로 변환하며, *llvm-dis*는 .bc 를 .ll 로 변환한다.

 컴파일러의 중간 표현은 최적화기를 위한 **완벽한 세상** 이라는 점에서 매우 흥미롭다. 컴파일러의 백엔드나 프론트엔드와는 달리 최적화기는 특정한 소스 언어나 타겟 머신의 제약을 받지 않는다. 한편으로는, 그 양쪽 모두와 관련이 있기도 하다. 프론트엔드가 소스 언어를 쉽게 변환해낼 수 있을 만큼 쉽고, 실제 코드에 적용될 수준의 중요한 최적화가 가능할 정도로 표현력이 있어야 한다.

 - Writing an LLVM IR Optimization

  최적화가 어떻게 일어나는지 감을 잡기 위해서는 예를 좀 살펴보는 것이 좋다. 컴파일러 최적화는 정말 많은 종류가 있고, 임의의 문제를 풀기 위한 레시피를 제공하는 것은 매우 어렵다. 대부분의 최적화는 간단한 3단계 구조를 가진다는 정도가 그나마 얘기할 수 있는 정도이다:

   1. 변환할 패턴을 찾는다
   #. 찾은 패턴에 대해 변환이 안전/정확한지 검증한다
   #. 변환을 수행하고 코드를 갱신한다

  *어떤 정수 X에 대해서, X-X=0, X-0=X, (X\*2)-X=X 이다* 와 같은 대수적 표현을 최적화하는게 가장 간단한 예가 될 수 있다. 일단 첫번째로 패턴 매칭을 하기 위해 LLVM IR 에서 이런 대수적 표현이 어떻게 표현되는지를 알아야 한다. 이런 예가 가능하다. ::

   ...
   %example1 = sub i32 %a, %a
   ...
   %example2 = sub i32 %b, 0
   ...
   %tmp = mul i32 %c, 2
   %example3 = sub i32 %tmp, %c
   ...

  이런 류의 구멍난 변환에 대해서, LLVM은 다른 고수준 변환에서 유틸리티로 사용될만한 명령어 단순화 인터페이스를 제공한다. 이런 변환은 ``SimplifySubInt`` 함수에 있으며, 아래와 같은 모양을 하고 있다. ::

   // X - 0 -> X
   if (match(Op1, m_Zero())
     return Op0;

   // X - X-> 0
   if (Op0 == Op1)
     return Constant:getNullValue(Op0->getType());

   // (X*2) - X -> X
   if (match(Op0, m_Mul(m_Specific(Op1), m_ConstantInt<2>())))
     return Op1;

   ...

   return 0; // Nothing matched, return null to indicate no transformation

  이 코드에서 Op0, Op1 은 각각 왼쪽, 오른쪽의 정수 피연산자에 해당한다. LLVM은 C++로 구현되었는데, C++은 다른 언어(Objective Caml이라거나...)에 비해 패턴 매칭을 잘 지원하는 편은 아니다. 대신 아주 일반적인 템플릿 시스템을 가지고 있는데, 이것으로 어느정도 비슷한 일을 할 수 있다. ``match`` 함수와 ``m_*`` 함수가 LLVM IR 코드에 대해서 이런 선언적인 패턴매칭을 수행한다. 예를 들어서 위의 ``m_Specific`` 은 곱하기 연산의 왼쪽 피연산자가 Op1 인 경우에만 매치되는 술부(predicate)이다.

  동시에, 위 함수는 이 3가지 경우 모두 매치되어 코드 변환이 일어나는 경우 변환될 코드를 리턴한다. 변환이 없는 경우 - 그러니까 매치되지 않은 경우 - 에는 널포인터를 리턴한다. 이 함수를 호출한 쪽(``SimplifyInstruction``)은 명령어 코드를 보고 각 명령어에 맞는 함수를 호출해주는 일종의 분배기이다. 이 분배기를 사용한 드라이버 코드는 아래와 같은 모양이다. ::

   for (BasicBlock::iterator I=BB->begin(), E=BB->end(); I!=E; ++I) {
     if (Value *V=SimplifyInstruction(I))
       I->replaceAllUsesWith(V);
   }

  이 코드는 단순히 블럭의 각 명령어를 살펴보면서 단순화시킬 수 있는 것이 있는지 확인한다. 만약 있다면(``SimplifyInstruction``이 null이 아닌 것을 리턴) ``replaceAllUsesWith``를 호출해서 단순화된 코드로 업데이트를 수행한다.

4. LLVM's Implementation of Three-Phase Design

 LLVM 기반의 컴파일러에서, 프론트엔드는 입력 코드의 파싱, 검증 및 에러 진단 그리고 파싱된 코드를 LLVM IR로 변환하는 일을 책임진다. 가끔은 LLVM IR 이 아닌 AST 를 생성하고 이 AST를 다시 LLVM IR로 변환하기도 한다. 여튼 이 IR은 코드를 개선할 수 있는 분석/최적화 패스를 연속적으로 통과한 후에, 마지막으로 기계어로 변환하기 위한 코드 생성기로 전달된다. 이것은 아주 명확한 3단계 설계의 구현인데, 이는 LLVM IR로부터 이끌어낸 LLVM 설계의 유연성과 강력함에 기반한다.

 .. image:: http://www.aosabook.org/images/llvm/LLVMCompiler1.png

 - LLVM IR is a Complete Code Representation

  LLVM IR은 최적화 모듈의 잘 정의된, 그리고 유일한 인터페이스다. 따라서 LLVM을 위한 프론트엔드를 만들기 위해서 알아야 할 것은, LLVM IR이 무엇인지, 어떻게 동작하는지 그리고 필요한 불변값은 무엇인지가 전부라고 할 수 있다. LLVM IR은 일차적으로 텍스트 형식을 가지고 있기 때문에 프론트엔드가 출력하는 LLVM IR은 텍스트 형식으로 하는 것이 가능하다. 뿐만 아니라 이는 꽤 괜찮은 선택이기도 한데, 유닉스 파이프를 사용해서 *bit-code* 로 변환할 수 있고, 최적화 모듈이나 코드 생성기에 바로 넘길 수도 있기 때문이다.

  놀라울 수도 있지만, 바로 이 특징이 LLVM 성공의 주요 요인 중 하나이다. GCC 처럼 비교적 잘 설계된 컴파일러조차도 이런 특징을 지니지 못했다. GCC의 GIMPLE이라는 중간 단계 표현은 스스로 완결되지 않는다. 예를 들어 GCC 코드 생성기가 DWARF 디버깅 정보를 생성할 때 뒤로 돌아가서 소스레벨 트리를 살펴본다. GIMPLE 그 자체도 명령어에 대해서는 **tuple** 표현을 사용하지만, 피연산자는 아직도 소스 트리에 대한 레퍼런스로 들고 있다.

  이게 암시하는 바는, GCC의 프론트엔드 작성자는 GIMPLE외에 GCC의 트리 자료구조 역시 알아야 한다는 뜻이다. GCC의 백엔드 역시 비슷한 문제를 가지고 있다. 마지막으로, GCC는 "전체 코드를 나타내는 무언가" 를 덤프하지 못하고, GIMPLE(과 이에 연관된 다른 자료구조들)을 텍스트 형식으로 읽고 쓸 수 있는 방법이 없다. 그 결과로 GCC 로 뭔가 실험적인 작업을 하는 것은 매우 어려우며, 프론트엔드의 수가 쉽게 늘기 어렵다.

 - LLVM IR is a Collection of Libraries

  LLVM에서 LLVM IR의 설계 다음으로 중요한 것은, GCC같이 한 덩어리의 컴파일러 바이너리, 혹은 JVM/.NET같은 가상머신이 아니라 **라이브러리 집합**으로 설계되었다는 점이다. LLVM은 특정 문제를 위해 고안된 여러가지 유용한 컴파일러 기술의 묶음으로써, 기반구조를 형성하고 있다. 바로 이 점이 가장 강력한 특징 중 하나이지만, 가장 잘 놓치는 디자인 포인트이기도 하다.

 예로 최적화 모듈의 설계를 한번 살펴보자: LLVM IR을 읽어들여서, 이것저것 처리를 하고, (아마도 더 빠르게 실행될) LLVM IR을 생성해낸다. 다른 컴파일러들과 마찬가지로 LLVM 에서 최적화는 독립적인 최적화 패스가 파이프라인으로 구성되어, 전 단계의 출력이 다음 단계의 입력이 된다. 간단한 '패스'의 예는 인라인 최적화, 대수식 재결합, 반복문의 불변값 위치 수정(http://en.wikipedia.org/wiki/Loop-invariant_code_motion) 등이 있다. 최적화 수준에 따라서 다른 패스가 실행된다. -O0 (NO OPTIMIZATION)에서는 아무런 최적화 패스도 실행되지 않고, -O3 에서는 67개의 최적화 패스가 실행된다(LLVM 2.8 기준)

 각 LLVM 패스는 *Pass* 클래스를 (간접적으로) 상속받은 C++ 클래스로 작성된다. 대부분의 패스는 하나의 .cpp 파일로 만들어지며, 클래스 구현은 익명 일므공간에 만들어져 파일 외부로부터 완전히 단절되며, 패스 구현체 클래스를 생성하기 위한 단 하나의 함수만이 바깥에 노출된다. ::

  namespace {
      class Hello : public FunctionPass {
      public:
          // Print out the names of functions in the LLVM IR being optimized
          virtual bool runOnFunction(Function &F) {
              cerr << "Hello: " << F.getName() << "\n";
              return false;
          }
      }
  }

  FunctionPass *createHelloPass() { return new Hello(); }

 LLVM 최적화는 아주 많은 패스를 제공한는데, 그 각각은 모두 비슷한 스타일로 작성되었다. 각 패스는 하나 혹은 여러개의 .o 파일로 컴파일되고 나서 여러개의 아카이브 라이브러리로 묶이고, 이 라이브러리가 분석/변환에 필요한 기능을 제공하게 된다. 각 패스는 최대한 서로에게 독립적이다. 패스 하나는 그 스스로 완결되어야 하며, 그렇지 않은 경우에는 명시적으로 의존성을 가지는(먼저 수행되어야 하는) 다른 패스를 지정해 주어야 한다. 실행해야 할 패스들이 주어지면, LLVM PassManager는 명시적 의존성 정보를 가지고 최적화 실행 순서를 정한다.

 라이브러리와 추상화된 기능들이 훌륭하긴 하지만, 실제적으로 문제를 해결해 주는 것은 아니다. 재미있는 부분은 누군가가 기존 컴파일러 기술로부터 새로운 툴을 만들려고 할 때 - 이미지 처리 언어를 위한 JIT 컴파일러라고 하자 - 생긴다. JIT 컴파일러의 구현자는 마음속으로 여러개의 제약사항을 가지고 있을 것이다. 예를 들면 이미지 처리 언어는 컴파일타임 응답성에 대단히 민감하다거나, 최적화를 위해 중요한 몇몇 언어적 특징을 가지고 있어야 한다거나.

 LLVM 의 라이브러리 기반의 설계 덕에, 이 구현자는 기존 패스들 중 이미지 프로세싱에 적합한 패스만 골라서 사용할 수 있다. 만약 하나의 큰 함수 하나로 만들어진 코드라면 인라인 최적화는 의미가 없을 것이다. 포인터를 거의 사용하지 않는다면, 별칭 분석(http://en.wikipedia.org/wiki/Alias_analysis)에 신경 쓸 필요가 없다. 우리가 아무리 최선을 다 한다 해도, LLVM 이 마법처럼 이런 문제를 해결해 줄 수는 없다. 패스 시스템은 모듈화 되어 있고 PassManager 자체는 패스의 구현 자체에 대해서는 전혀 모른다. 만약 구현하는 언어에 적당한 최적화 패스가 LLVM 에 없다면 직접 패스를 만들어 사용하는 것도 자유이다.

 .. image: http://www.aosabook.org/images/llvm/PassLinkage.png

 일단 최적화 패스들이 선택되면, 이미지 처리 컴파일러는 실행파일로 만들어지던가 동적 라이브러리로 빌드된다. LLVM 최적화 패스의 레퍼런스는 "create" 함수 뿐이고, 최적화기는 .a 아카이브 파일에 있기 때문에 최종 결과물에는 실제로 최종 프로그램이 사용하는(create를 호출한) 패스만이 링크된다. 위의 예를 보면, createPassA 와 createPassB 를 실행했기 때문에 LLVMPasses.a 에 있는 패스 중 PassA, PassB 그리고 PassB가 의존성을 가지는 PassD 만이 링크에 사용된다. 그리고 사용자가 직접 작성한 createXYZPass 도 사용했기 때문에 PassXYZ.o 역시 링크에 사용된다. 하지만 어디에서도 사용하지 않은 PassC 는 최종 결과물에 포함되지 않는다.

 이상의 예가 LLVM 의 라이브러리 기반 설계가 힘을 얻는 부분이다. 이 명쾌한 설계 접근 방식으로 인해 LLVM은 많은 기능을 갖추었다. 이 기능 중 일부는 특정한 사용자들에만 유용한 것인데, 이러한 일부분만을 사용하더라도 문제가 되지 않는다. 반면 전통적인 컴파일러 최적화기는 서로 긴밀하게 연결된 거대한 코드 묶음으로 만들어져 있어서 일부분만을 분리해내기가 매우 어렵다. LLVM 설계 아래에서는 전체를 한데 묶지 않아도 각 최적화 패스의 동작을 이해하는 것이 가능하다.

 라이브러리 기반 설계는 많은 사람들이 LLVM 이 무엇인지에 관해 오해하게 되는 원인이기도 하다. LLVM 라이브러리는 여러가지 기능을 가지고 있지만, 그 스스로는 아무것도 하지 않는다. 라이브러리의 각 조각을 어떻게 사용할지는 사용자의 몫이다. 예를 들면 CLang C 컴파일러처럼 ... 이렇게 전체 기능의 부분집합을 구성하기 쉽도록 해둔 설계가 LLLVM 최적화가 넓은 분야의 서로 다른 어플리케이션에서 사용될 수 있는 원동력이다.

5. Design of the Retargetable LLVM Code Generator

 LLVM 코드 생성기는 LLVM IR 을 "가능한 한 최선의" 타겟 머신코드로 변환하는 일을 담당한다. 이상적으로는 각 타겟마다의 코드 생성기는 완전히 별도의 구현이 될 수 있지만, 한편으로는 각 코드 생성기가 하는 작업들은 매우 비슷하다. 예를 들어, 각 타겟들은 레지스터에 값을 넣을 필요가 있는데 서로 다른 레시스터 구성을 가지고 있다 해도 알고리즘 자체는 가능한 한 공유될 수 있다.

 최적화 할 때와 비슷하게, 코드 생성기도 코드 생성 문제를 명령어 선택, 레지스터 할당, 스케쥴링, 코드 레이아웃 최적화, 어셈블리 생성 등 여러개의 독립적인 패스로 쪼갠다. 그리고 기본으로 실행되는 많은 빌트인 패스로 일반적인 구현을 가지고 있다. 특정 타겟에 대해 코드 생성기를 작성하는 사람은 기본 패스 중에서 골라 사용하거나, 타겟에 맞는 커스텀 패스를 만들어 넣을 수 있다. 예를 들면 X86 백엔드는 레지스터 수가 별로 없기 때문에 register-pressure-reducing 스케쥴러를 사용한다. 하지만 PowerPC 백엔드는 레지스터 수가 많기 때문에 latency 최적화 스케쥴러를 사용한다. 또, X86 백엔드는 x87 부동소수점 스택을 다루기 위해 커스탬 패스를 사용하고, ARM 백엔드에서는 함수 안에 상수 풀을 구성하기 위한 커스탬 패스를 사용한다. 이런 유연한 설계에 힘입어 코드 생성기 작성자는 그들의 코드 생성기를 밑바닥부터 완전히 새로 구성하지 않고도 훌륭하게 작동시킬 수 있다.

 - LLVM Target Description Files

  이런 "섞어서 매치하는" 접근으로 코드 생성기 작성자들은 각자의 아키텍쳐에 맞는 코드 조각을 재사용할 수 있다. 이것이 또 다른 도전거리를 낳는다: 각 공유 컴포넌트는 일반적으로 동작하면서 각 타겟 머신마다의 고유한 특징을 반영해야 한다. 예를 들면 공유 레지스터 할당기는 각 타겟의 레지스터 구성과 레지스터들의 사용 제한 등을 알아야 한다. LLVM 은 이를 위해 전용 언어로(DSL) 각 타겟에 대해서 Target description(.td 파일)을 제공하는 방식을 택했다.

  .td 파일로 생성되는 각 서브시스템은 해당 타겟의 여러 다른 조각을 생성해낸다. X86 백엔드는 "GR32"라는 이름의 모든 32-bit 레지스터를 담고 있는 레지스터 클래스를 아래와 같이 정의한다. ::

   def GR32 : RegisterClass<[i32], 32,
       [EAX, ECX, EDX, ESI, EDI, EBX, EBP, ESP,
        R8D, R9D, R10D, R11D, R14D, R15D, R12D, R13D]> { ... }

  .. image: http://www.aosabook.org/images/llvm/X86Target.png

  이 레지스터 클래스는 32-bit 정수값을 가질 수 있고(i32), 32-bit aligned 을 선호하는 16개의 레지스터를 가지고 있으며(.td 파일의 다른곳에 정의된다), 기타 다른 할당 순서 등의 정보를 가지고 있다. 이 정의 파일이 주어지면 특정 명령어들이 이를 참조하며 피연산자로 사용할 수 있다. '32bit register 의 보수 구하기' 명령은 아래와 같이 정의된다. ::

   let Constraints = "$src = $dst" in
   def NOT32r : I<0xF7, MRM2r,
                  (outs GR32:$dst), (ins GR32:$src),
                  "not{l}\t$dst",
                  [(set GR32:$dst, (not GR32:$src))]>;

  이 명령어의 정의는 다음과 같은 내용을 담고 있다:
   - NOT32r 은 인스트럭션이다 - (I tblgen class)
   - 인코딩 정보는 (0xF7, MRM2r)
   - 출력은 32-bit 레지스터 $dst, 입력은 32-bit 레지스터 $src 로 위에서 정의된 GR32 레지스터 클래스에 속한다
   - 이 명령어에서 생성되는 어셈블리 문법을 지정한다
   - 이 명령어의 효과 및 패턴을 기술한다

  제일 위의 let 은 $src와 $dst가 같은 물리적 레지스터에 할당되어야 한다는 것을 나타낸다

  이 정의는 매우 압축적인 기술이다. LLVM 코드는 이 정의로부터 얻을 수 있는 정보로(tblgen 툴을 사용) 많은 것을 할 수 있다. 이를테면, 이 한 정의만 있으면 IR 코드에 대한 패턴 매칭을 통해 명령어 선택을 하기 위해 충분하다. 또한 레지스터 할당자에게 어떻게 레지스터를 다룰지 알려주며, 명령어를 기계어도 인코딩/디코딩 하는 데에도 충분하며, 명령어를 파싱해서 텍스트 형식으로 출력하는 데에도 부족함이 없다. 이런 기능들 덕에 x86 어셈블러/역어셈블러를 target description 으로부터 생성해 낼 수가 있으며, JIT 을 위해 명령어를 인코딩 할 수도 있다.

  이런 기능적인 이점 외에도 같은 사실로부터 생성된 여러개의 정보 조각을 가지는 것은 또다른 이점이 있다. 이런 접근은 어셈블러와 역어셈블러가 문법이나 바이너리 인코딩 등의 문제에서 서로 아귀가 맞지 않는 일이 생기는 것을 원천적으로 방지한다. 또한 target description 을 보다 쉽게 테스트 할 수 있기도 하다: 명령어 인코딩은 전체 코드 생성기를 통하지 않고도 유닛 테스트가 가능하다.

  target description 파일이 여러가지 역할을 훌륭해 해 주긴 하지만, 어느정도의 C++ 코드 작업은 여전히 필요하다. LLVM 이 계속 새로운 타겟을 지원해 나가면서, 보다 많은 타겟이 .td 로 표현될 수 있어야 할 것이다. 당연히 .td 파일로 표현할 수 있는 범위가 더 넓어져야 한다. 이 접근 방식의 큰 이점은 LLVM 프로젝트가 진행되어 가면서 새 타겟을 추가하는 일은 점점 더 쉬운 일이 된다는 점이다.

6. Interesting Capabilities Provided by a Modular Design

 - Choosing when and where each phase runs

  LLVM IR은 LLVM bitcode 라는 바이너리 포맷으로 효율적으로 변환/역변환 될 수 있다. LLVM IR 은 스스로 완결되어 있고, 변환이 정보 손실이 없는 과정이기 때문에 컴파일 작업을 일부만 하고 디스크에 저장해 두었다가 나중에 그 시점에서 작업을 재개하는 것이 가능하다. 이 특징은 여러가지 흥미로운 기능으로 이어지는데, 예를 들면 링크시점/설치시점 최적화가 그것이다. 두 경우 모두 코드 생성을 컴파일 시점으로부터 연기시키는 것이 핵심이다.

  링크시점최적화(LTO-Link Time Optimization)은 전통적인 컴파일러가 하나의 변환 유닛만을(.h+.c) 보기 때문에 파일 경계를 넘는 최적화를 하지 못하는 상황에 문제를 제기한다. CLang 같은 LLVM 컴파일러들은 -flto 혹은 -O4 옵션으로 이런 기능을 지원한다. 이 옵션은 컴파일러에게 .o 파일에 머신코드 대신 LLVM bitcode 를 생성하도록 하고, 코드 생성을 링크 시점까지 늦추는 일을 한다.

  .. image: http://www.aosabook.org/images/llvm/LTO.png

  자세한 작업은 OS 마다 다르겠지만, 중요한 점은 링커가 .o 파일에 머신코드 대신 LLVM bitcode 가 있다는 사실을 감지해내는 것이다. 링커가 이를 감지하게 되면, bitcode 를 모두 읽어 메모리에 적재하고 링크한 후에 LLVM 최적화 패스를 합쳐진 LLVM bitcode 에 대해서 돌린다. 코드의 보다 많은 부분을 볼 수 있기 때문에 인라이닝, 상수 전달, 보다 공격적인 죽은 코드 제거 등등을 파일 경계를 넘어서 할 수 있게 된다. 많은 현대적 컴파일러들이 LTO 를 지원하지만, 그들 대부분은(GCC, Open64, Intel Compiler) 매우 비싸고 느린 직렬화 프로세스를 통하여 이런 작업을 한다. LLVM 에서는 LTO 가 시스템의 기본적인 디자인 틀 안에서 처리되며, 심지어 서로 다른 소스 언어들끼리도 동작한다.

  설치시점 최적화는 코드 생성을 링크시점보다 더 뒤로 미룬다. 설치 시점은 타겟 디바이스의 세부 사항이 밝혀지는 때라는 점에서 대단히 흥미롭다. x86 계열에도 그 안에는 여러가지 특성들이 폭넓게 분포한다. 명령어 선택, 스케쥴링이나 다른 코드 생성을 미룸으로써, 어플리케이션이 실제로 돌아갈 특정 하드웨어에 최선의 선택을 할 수 있게 되는 것이다.

  . image: http://www.aosabook.org/images/llvm/InstallTime.png

 - Unit Testing the Optimizer

  컴파일러는 매우 복잡하고, 성능 및 퀄리티가 매우 중요하다. 따라서 테스트는 아주 핵심적인 부분이다. 예를 들어 최적화 과정에서 죽는 버그를 잡은 후에, 이 문제가 다시 발생하지 않는다는 것을 확인하기 위한 리그레션 테스트가 반드시 추가되어야만 한다. 테스트를 작성하는 종래의 접근은 컴파일러를 통해 실행되는 .c 파일을 만들고 컴파일러가 다시 죽지 않는 것을 확인하는 것이었다. 이게 GCC 테스트 수트의 방식이다.

  하지만 컴파일러는 여러개의 서로 다른 서브시스템과 훨씬 더 많은 최적화 패스로 구성되어 있다. 이 모두가 입력 코드의 변화에 매우 민감하게 반응할 수 있다. 만약 프론트엔드나 최적화 초기 단계에 변화가 생긴다면 테스트는 쉽게 실패해 버릴 수 있다.

  LLVM IR의 텍스트 형식와 최적화 모듈을 사용한 결과, LLVM 테스트 수트는 리그레션 테스트를 매우 효율적으로 하게 되었다. LLVM IR을 디스크에서 읽어서 단 하나의 최적화 패스에만 넣어 돌려보고, 기대한 결과가 나오는지를 확인한다. 죽는 것 이외에도, 훨씬 복잡한 동작 테스트를 할 수 있다. 상수 전파(?) 패스가 더하기 명령어에 대해 제대로 동작하는지 확인하는 테스트 케이스는 아래와 같다. ::

   ; RUN: opt < %s -constprop -S | FileCheck %s
   define i32 @test() {
       %A = add i32 4, 5
       ret i32 %A
       ; CHECK: @test()
       ; CHECK: ret i32 9   
   }

  RUN 이 있는 줄은 실행할 명령어를 지정한다. opt 와 FileCheck 는 커맨드라인 툴이다. opt 는 LLVM 패스 매니저의 간단한 wrapper인데, 모든 표준 패스를 링크해서 커맨드라인을 통해 실행할 수 있게 해둔 것이다. FileCheck 은 표준 입력으로 들어오는 내용이 CHECK 지시자와 일치하는지를 확인한다. 이 경우 4와 5를 더한 값이 9로 제대로 바뀌는 지를 확인한다.

  이 예가 아주 자명하고 간단해 보이지만, 이 테스트를  .c 파일을 만들어서 하기란 대단히 어렵다. 프론트 엔드가 파싱하면서 상수를 묶어 버리는 경우도 있기 때문에 실제로 Constant Folding Optimization 패스에서 저 작업이 일어나도록 코드를 만드는 것이 매우 어렵고 안정적이지 않은 작업이다. 우리는 LLVM IR을 텍스트로 읽어들이고 특정 최적화 패스에 바로 보내고, 그 결과를 또다른 텍스트 파일로 덤프하는 것도 가능하다. 이것을 조합하면 기능/회귀 테스트 둘 모두에 대해서 아주 직관적이면서도 원하는 것만을 정확히 해내는 테스트를 작성할 수 있다.

 - Automatic Test Case Reduction with BugPoint

  컴파일러나 LLVM 라이브러리의 다른 클라이언트에서 버그가 발견되면, 수정을 위한 첫 번째 작업은 문제를 재현하는 테스트 케이스를 얻어내는 일이다. 일단 테스트 케이스가 확보되면, 문제를 재현할 수 있는 한도 내에서 해당 케이스를 가능한 한 작게 만들어 문제가 발생하는 LLVM의 문제 지점에 바로 접근하도록 한다. 이 과정은 매우 지루하고, 고통스러운 작업인데 특히나 컴파일러가 죽지는 않으면서 "올바르지 않은 코드"를 생성하는 경우에는 더 그렇다.

  LLVM BugPoint 는 IR 직렬화와 모듈화된 디자인을 사용해서 이 작업을 자동화했다. 예를 들어, .ll, .bc 파일과 함께 프로그램이 비정상 종료하도록 만드는 최적화 패스 리스트가 있는 경우에 BugPoint는 입력을 작은 테스트 케이스로 줄이고 어떤 최적화 패스가 문제인지를 찾아내어 테스트 케이스와 opt 툴을 이용한 문제 재현 커맨드를 내놓는다. 입력 테스트 케이스와 최적화 패스 리스트를 줄여가기 위해 사용하는 기법은 '델타 디버깅'과 유사한 방법이지만 BugPoint 는 LLVM IR 의 구조를 이해하고 있기 때문에 다른 델타 디버깅 툴과 달리(http://delta.tigris.org/, ...) 유효하지 않은 LLVM IR 를 생성하느라 시간을 낭비하지 않는다. 

  보다 복잡한 컴파일 오류같은 경우에도 입력과, 코드 생성기 정보, 실행파일에 넘길 명령, 레퍼런스 출력을 지정할 수 있다. 그러면 BugPoint 는 일단 문제가 최적화 쪽에 있는지 아니면 코드생성기 쪽인지를 결정한다. 그리고 테스트 케이스를 두개로 쪼개가며 "문제 없음", "문제 있음" 의 두 개의 그룹으로 분류해 가며 테스트 케이스 크기를 줄인다.

  BugPoint는 매우 단순한 도구이지만 LLVM 프로젝트 전체적으로 이를 통해 절약한 시간은 엄청나다. 다른 어떤 오픈소스 컴파일러도 이러한 도구를 지니고 있지 않다. 이는 잘 정의된 LLVM IR에 기반하고 있기 때문이다. BugPoint는 완벽하지 않고, 재작성하는게 나을 수도 있다. 2002년부터 기존의 툴로는 찾아내기 힘든 절묘한 버그들을 잡을 때에 사용되며 개선되어 왔으며, 상시 관리자나 특정 설계에 기반하지 않고 계속 발전해 나가고 있다.

7. Retrospective and Future Directions

 LLVM의 모듈화는 여기 소개된 목적들을 직접적으로 달성하기 위해 설계된 것은 아니다. 이것은 자기방어 메커니즘이라고 할 수 있다. 처음부터 완벽했던 것은 아니다. 파이프라인 패스 설계는 나중에 더 나은 구현이 생기면 바꿔넣기 좋게 하기위해 패스를 독립적으로 만들려다 보니 생긴 것이다.

 그리고 하위호환성을 고려하지 않고 이전의 결정을 재고하고 API의 넓은 범위에 걸친 변화를 주는 등의 발빠른 개발이 LLVM의 또 다른 한면이다. LLVM IR 자체에 대한 변화는 모든 최적화 패스의 수정과 더불어 C++ API 에도 많은 영향을 준다. 이런 큰 작업은 분명 힘든 일이지만, 몇 번이나 해 왔다. 빠르게 앞으로 나아가는 것이 옳바른 것이다. 라이브러리 사용자들이 너무 고생하지 않도록 우리는 자주 쓰이는 API들의 C wrapper를 제공하고 있으며, 새 버전의 LLVM 이 이전 버전의 .bc, .ll 파일을 읽을 수 있도록 하고 있다.

 LLVM은 보다 더 모듈화되고 부분집합을 취하기 쉬운 형태로 발전해갈 예정이다. 코드 생성기는 아직 모듈화가 덜 되어 있다: 피처에 기반한 LLVM 부분집합을 생성하는 것이 불가능하다. JIT은 사용하지만 인라인 어셈블리, 예외처리, 디버그 정보 생성등이 필요 없는 경우에 사용하지 않는 기능을 제외하고 링크해서 코드 생성기를 만들어내는 것이 가능해야 할 것이다. (최적화에선 가능하지...) 또 최적화 패스나 코드생성기를 통하여 생성된 코드의 품질도 계속 향상시켜 나가고 있다. 그 외에도 IR 기능이나 고수준 최적화 등에 대해서 계속 지원을 확대해 가고 있다.

 ....

Compiler design
    Three phase: Frontend -> Optimizer -> Backend
    What's the strength of three-phase design?
    Success stories:
        Java and .NET virtual machines
        Translate input source code into C
        GCC
    Why one more?

LLVM IR
    Ref: http://llvm.org/docs/LangRef.html
    LLVM IR is a low-level RISC-like virtual instructino set.
    Like most RISC instruction sets:
        * Support leniar sequence of simple instructions: add, sub, compare and branch
        * Three-address form
        * Support labels
    Unlike most RISC instruction sets:
        * Strongly typed with a simple type system
        * Some details of the machine are abstracted
        * Uses an infinite set of temporaries named with a % character
    Defined in three isomorphic form:
        * Textual (.ll)
        * In-memory structure
        * Bitcode (.bc)
        * llvm-as: .ll -> .bc
        * llvm-dis: .bc -> .ll
    Intermediate representation can be a 'perfect world' for the compiler optimizer
    Should be easy for a frontend to generate
    Should be expressive enough to allow important optimizations to be performed for real targets


Three-phase

    * Frontend: Parsing, validating and diagnosing erros. Then traslate parsed code into LLVM IR
    * Optimizer: Takes LLVM IR and write out LLVM IR.
    * Code generator: Convert LLVM IR into machine code
    Looks like pipelining, and it really is.


    * LLVM IR is complete code representation
    * LLVM is a collection of libraries

