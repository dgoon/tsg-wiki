---
format: rst
title: LLVM on AOSABOOK
...

 이 챕터는 LLVM 을 만들어온 디자인 결정사항들에 대해 이야기한다. LLVM은 어셈블러, 컴파일러, 디버거 등의 저수준 툴체인 셋을 아우르는 프로젝트이다. 기존 유닉스 시스템에서 쓰이던 툴과 호환되도록 디자인 되었다. "LLVM"은 원래 약자였지만(Low-Level Virtual Machine) 이제는 관련 프로젝트를 총괄하는 프로젝트 브랜드가 되었다. LLVM은 그 자체만의 기능 뿐 아니라 훌륭한 관련 도구들(CLang 같은...)로도 유명하지만, LLVM 을 다른 컴파일러들과 구분해주는 가장 큰 특징은 그 아키텍쳐에 있다.

 2000년 12월에 처음 프로젝트가 시작되었을 때 부터, LLVM은 잘 정의된 인터페이스를 가진 **재사용 가능한 라이브러리 모음**이 되도록 디자인되었다. 당시에 오픈소스 프로그래밍 언어의 구현들은 보통 하나의 실행파일로 이루어진 특정 용도 전용으로 설계되었다. 예를 들어 정적인 컴파일러로부터 파서를 뽑아내서 정적분석이나 리팩토링을 위해 재사용하는 것은 매우 어려운 일이다. - GCC를 생각해보라! 반면 스크립트 언어들은 보다 큰 프로그램에 런타임/해석기를 내장하는 경우가 많은데, 보통 그 런타임은 하나의 거대한 코드덩어리로 그 일부를 재사용하는 것도 어려울 뿐더러 여러 언어 구현에 공유되는 경우도 거의 없다.

 컴파일러 그 자체의 구성 이외에도, 인기있는 언어 구현체를 사용하는 커뮤니티는 보통 대단히 편중되어 있다. 구현체는 보통 전통적인 컴파일러(GCC, FreePascal같은...)를 제공하거나 혹은 인터프리터나 JIT(Just-In-Time) 컴파일러를 제공한다. 이 양쪽을 모두 지원하는 언어 구현체를 대단히 희귀하고, 있던 경우에도 이 양쪽 구현은 거의 코드를 공유하지 않았다.

 지난 10년간 LLVM은 이런 구도를 상당히 많이 바꾸어 냈다. LLVM은 요즘 정적 컴파일러, 런타임 컴파일러 양쪽 전반에 걸쳐 폭넓게 사용되는 전반 기술이다. 또한, 여러개의 특수화된 전용 컴파일러를 대체하기도 했다. 예를 들면, 애플의 OpenGL 스택이나 어도비 After Effect의 이미지 프로세싱 라이브러리 같은 부분에 사용되었다. 마지막으로 LLVM은 새 제품을 만드는 데에도 많이 사용되는데, 아마 가장 잘 알려진 것은 OpenCL GPU 프로그래밍 언어와 런타임일 것이다.

1. A Quick Introduction to Classical Compiler Design

 전통적인 정적 컴파일러(대부분의 C 컴파일러)의 가장 흔한 설계는 3단계 설계이다. 3단계 설계는 프론트엔드(Frontend), 최적화모듈(Optimizer), 백엔드(Backend)의 3개 컴포넌트로 구성된다.

 .. image:: http://www.aosabook.org/images/llvm/SimpleCompiler.png

 각 컴포넌트는:

Frontend
  소스코드 파싱, 에러검사, 입력 코드를 나타내는 언어마다의 `AST<http://en.wikipedia.org/wiki/Abstract_syntax_tree>`_(Abstract Syntax Tree) 를 생성하는 일을 한다. AST는 최적화를 위해 별도의 형식으로 표현될 수 있다.

Optimizer
  코드의 실행 속도를 향상시키기 위한 여러가지 변환 작업(예: 중복 계산 제거)을 한다. 이런 작업은 보통 언어/타겟 아키텍쳐와 독립적이다.

Backend
  코드 생성기라고도 한다. 코드를 타겟 명령어셋에 맞도록 변환한다. *올바른* 코드를 생성하는 것은 물론이고, 아키텍쳐에서 지원하는 특징을 잘 사용하여 *좋은* 코드를 생성해야 한다. 컴파일러 백엔드는 보통 명령어 선택, 레지스터 할당, 명령 스케쥴링 등을 작업을 한다.

 이 모델은 인터프리터나 JIT 컴파일러에도 똑같이 잘 적용된다. 자바 가상 머신(JVM)도 자바 바이트코드를 프론트엔드와 최적화 사이의 인터페이스로 사용하는 이 모델-3단계 디자인-의 구현체이다.

 - Implications of this Design

  이 클래식한 설계의 가장 중요한 이점은 컴파일러가 여러가지 소스 언어, 혹은 여러개의 타겟 아키텍쳐를 지원하고자 할 때 생긴다. 만약 컴파일러가 최적화 단계에서 하나의 코드 표현을 사용한다면, 프론트엔드는 어떤 언어라도 그 코드 표현으로 컴파일 하기만 하면 되고, 백엔드는 그 코드 표현에 대해서만 만들어지면 된다. 아래 그림을 참고하자.

  .. image:: http://www.aosabook.org/images/llvm/RetargetableCompiler.png

  이 설계에서는, 새로운 소스 언어를 지원하기 위한 작업은 새 프론트엔드의 구현 뿐이다. 기존의 최적화 모듈과 백엔드는 재사용할 수 있기 때문이다. 만약 각 부분들이 분리되어 있지 않다면, 새 소스 언어의 구현은 바닥부터 작업해야 하는 일이 되고, N 개의 타겟과 M 개의 소스 언어를 지원하기 위해서 N*M 개의 컴파일러를 필요로 하게 된다.

  3단계 구현의 또 다른 이점은 (위의 장점과 직접적으로 연관되었다) 여러개의 언어를 지원함으로써 컴파일러가 더 넓은 프로그래머들에게 쓰일 수 있고, 따라서 더 큰 커뮤니티를 형성할 수 있다는 점이다. 더 큰 커뮤니티는 더 많은 기여자를 이끌어내고, 자연스럽게 더 많은 개선이 가능하다. 이게 바로 GCC 같이 많은 커뮤니티에서 쓰이는 컴파일러가 FreePASCAL같이 좁은 범위에서 사용되는 컴파일러보다 최적화가 잘 된 기계어를 생성해내는 이유가 된다. 하지만 상용 컴파일러같은 경우에는 예산이 코드의 질로 바로 연결되기 때문에 경우가 조금 다르다고 할 수 있다. 예를 들어서 ICC 컴파일러는 좁은 사용자층에도 불구하고 훌륭한 코드를 생성해 낸다고 알려져 있다.

  3단계 구현의 마지막 이점은, 각 3개 컴포넌트를 구현하는데 필요한 기술이 다르다는 점이다. 필요 기술을 분리하는 것은 각 컴포넌트를 작업하는 사람이 맡은 부분을 개선하고 유지해나가는 것을 보다 쉽게 만들어준다. 이것이 기술이 아닌 **사회적**인 이슈이긴 하지만 실제적으로 아주 중요하다. 특히나, 이런 오픈소스 프로젝트가 기여를 받기 위한 진입장벽을 낮추는 데에 크게 도움이 된다.

2. Existing Language Implementation

 3단계 디자인의 이점이 명백하고, 관련 교과서 등에 잘 설명되어 있지만 실제적으로 실현된 경우는 거의 없다. LLVM이 시작되었던 시기로부터 뒤돌아 오픈소스 언어 구현체를 살펴보면, Perl, Python, Ruby, Java 등의 구현체가 공유하는 코드가 없다는 것을 알 수 있다. 또한, Glasgow Haskell Compiler(GHC)나 FreeBASIC 같은 언어들은 여러 다른 CPU를 지원하지만 그 구현들은 지원하는 소스 언어에 대단히 의존적이다. 그 외에도 이미지 프로세싱에 쓰이는 JIT 컴파일러, 정규식, 그래픽 카드 드라이버 등 CPU 작업이 주를 이루는 특수 목적의 컴파일러 기술도 많다.

 정리해보면 이 모델의 성공 스토리로 주요한 3개의 예가 있다. 그 **첫번째** 는 자바와 .NET 의 **가상머신**이다.

 **두번째** 성공의 예는 아마도 가장 불운한, 하지만 컴파일러 기술을 재사용하는 가장 인기있는 방법일 것이다. 바로 - **입력 소스 코드를 C 코드로 변환**하여 기존의 C 컴파일러에게 보내는 것이다. 이 방법은, 최적화기, 코드 생성기 등을 재사용할 수 있으며 매우 유연하고, 프론트엔드를 구현하는 사람이 이해하기 쉽고 유지보수도 쉽다. 하지만 이 방법은 효율적인 예외 처리를 방해하며, 디버깅 환경도 매우 좋지 않다. 또한 컴파일 시간도 오래 걸리고 C에서 지원하지 않는 특징을 지원하는 언어에 대해서는 문제의 소지가 있다.

 **마지막** 예는 바로 **GCC** 이다. GCC는 여러 프론트엔드, 백엔드를 지원하며 여러 커뮤니티에 걸쳐 활발하게 활동하는 기여자들을 가지고 있다. GCC 는 여러 타겟을 지원하는 C 컴파일러로 오랜 시간을 보냈고, 당시에는 다른 몇몇 언어를 지원하기 위해 여러 꽁수를 사용했다. 시간이 지나며 GCC 커뮤니티는 점차적으로 보다 깨끗한 설계로 진화했다. GCC 4.4에 이르러서는 최적화기를 위한 새로운 표현 방식(`GIMPLE Tuples<http://gcc.gnu.org/wiki/tuples/>`_)이 생겼는데 전에 비해 프론트엔드와 보다 분리되는 쪽의 변화이다. 또한 GCC의 포트란/ADA 프론트엔드는 깔끔한 AST를 사용한다.

 이런 시도들이 매우 성공적이었지만, 한편 기본적으로 monolithic 방식으로 설계되었기 때문에 이런 접근 방식에 한계가 있을 수밖에 없었다. 한 예로, GCC 를 다른 어플리케이션에 포함시키거나, GCC를 런타임/JIT 컴파일러로 사용하거나, 혹은 컴파일러의 대부분을 가져오지 않고 GCC의 일부만 재사용하는 일은 거의 불가능하다. GCC의 C++ 프론트엔드를 문서 생성기, 코드 인덱싱, 리팩토링, 정적 분석기 등에 사용하고 싶은 사람은 GCC가 생성하는 XML을 사용하기 위해 통짜로 사용하거나, 다른 코드를 GCC 프로세스에 끼워 넣는 플러그인을 만들어야만 한다.

 GCC의 각 조각들이 라이브러리로 사용될 수 없는 이유는 여러 가지가 있다. 전역 변수의 남발, 거의 강제되지 않은 불변값, 잘못 설계된 자료구조, 조각조각 파편화된 코드베이스, 한번에 하나의 프론트엔드/타겟 페어로만 빌드할 수 있는 매크로 사용 등. 하지만 가장 고치기 어려운 문제는, 초기 설계로부터 전해내려오는 구조적인 결함이다. 특히, GCC는 추상화 단계가 잘 갖추어지지 않아 레이어링에 문제를 겪고 있다. 즉, 백엔드에서 디버그 정보를 생성하기 위해 프론트엔드의 AST를 뒤져야 한다거나, 프론트엔드가 백엔드의 자료구조를 생성한다거나, 전체 컴파일러가 커맨드라인에 의해 설정된 전역 자료구조에 크게 의존하는 등의 문제가 있다.

3. LLVM's Code Representation: LLVM IR

 이런 역사적인 배경지식을 가지고 LLVM을 한번 살펴보자. 설계의 가장 중요한 부분은 바로 **LLVM Intermediate Representation(IR)** 이다. LLVM IR은 컴파일러가 코드를 나타내기 위해 사용하는 스펙으로, 중간 단계의 분석 및 최적화 변환에 사용한다. 여러가지 확실한 목적을 염두에 두고 설계되었는데, 그 중에는 가벼운 런타임 최적화, 여러개의 함수/프로시저를 통합한 최적화, 전체 프로그램 분석, 공격적인 재구조화 변환 등이 있다. 핵심은, LLVM IR 자체가 잘 정의된 의미를 가진 언어라는 점이다. 여기 구체적인 예가 있다.::

  define i32 @add1(i32 %a, i32 %b) {
  entry:
    %tmp1 = add i32 %a, %b
    ret i32 %tmp1
  }

  define i32 @add2(i32 %a, i32 %b) {
  entry:
    %tmp1 = icmp eq i32 %a, 0
    br i1 %mp1, label %done, label %recurse

  recurse:
    %tmp2 = sub i32 %a, 1
    %tmp3 = add i32 %b, 1
    %tmp4 = call i32 @add2(i32 %tmp2, i32 %tmp3)
    ret i32 %tmp4

  done:
    ret i32 %b
  }

 위의 LLVM IR로 작성된 두 함수는 각각 아래의 C 코드를 표현하는 것으로, 두 정수를 더하는 서로 다른 방법이다.::

  unsigned add1(unsigned a, unsigned b) {
    return a+b;
  }

  unsigned add2(unsigned a, unsigned b) {
    if (a==0) return b;
    return add2(a-1, b+1);
  }

 위의 예에서 볼 수 있듯 LLVM IR은 저수준의 RISC와 같은 가상 명령어 집합이다. **실제 RISC와 같이** *더하기, 빼기, 비교, 분기* 등의 간단한 명령어들을 지원한다. 이 명령들은 3-주소-형식인데, 이는 명령어가 몇 개의 입력을 받고, 입력이 아닌 다른 레지스터에 결과를 저장한다는 것을 의미한다. LLVM IR은 레이블도 지원하고, 일반적으로는 좀 이상한 형태의 어셈블리 언어처럼 보인다.

 대부분의 RISC 명령어 집합과 다른 점으로는, LLVM IR은 간단한 타입 시스템을 가진 **강 타입** 언어이고, 실제 기계의 상세한 부분을 추상화시켜 버렸다는 부분을 들 수 있다. 예를 들어 *call*, *ret*와 명시적인 인자 전달을 통하여 호출 규약(calling convention)을 추상화시켜 버렸다. 기계어와 또 다른 중요한 차이점은 레지스터의 수이다. LLVM IR 은 임시로 이름을 붙일 수 있는 무한한 수의 레지스터를 가질 수 있따. 임시 이름은 **%**를 앞에 붙임으로써 생성할 수 있다.

 언어로써의 구현 이외에, LLVM IR은 3가지의 서로 동등한 형태로 정의된다. 각각 위에 설명한 *텍스트 형식*, 최적화를 위해 변경되고 조사하기 위한 *메모리 적재 자료구조*, 마지막으로 디스크에 저장하기 위한 압축적인 *bit-code* 형식이다. LLVM 프로젝트는 각 포맷간의 변환을 위한 툴을 제공한다. *llvm-as* 는 텍스트 형식(.ll)을 bit-code(.bc)로 변환하며, *llvm-dis*는 .bc 를 .ll 로 변환한다.

 컴파일러의 중간 표현은 최적화기를 위한 **완벽한 세상** 이라는 점에서 매우 흥미롭다. 컴파일러의 백엔드나 프론트엔드와는 달리 최적화기는 특정한 소스 언어나 타겟 머신의 제약을 받지 않는다. 한편으로는, 그 양쪽 모두와 관련이 있기도 하다. 프론트엔드가 소스 언어를 쉽게 변환해낼 수 있을 만큼 쉽고, 실제 코드에 적용될 수준의 중요한 최적화가 가능할 정도로 표현력이 있어야 한다.

 - Writing an LLVM IR Optimization

  최적화가 어떻게 일어나는지 감을 잡기 위해서는 예를 좀 살펴보는 것이 좋다. 컴파일러 최적화는 정말 많은 종류가 있고, 임의의 문제를 풀기 위한 레시피를 제공하는 것은 매우 어렵다. 대부분의 최적화는 간단한 3단계 구조를 가진다는 정도가 그나마 얘기할 수 있는 정도이다:

   1. 변환할 패턴을 찾는다
   #. 찾은 패턴에 대해 변환이 안전/정확한지 검증한다
   #. 변환을 수행하고 코드를 갱신한다

  *어떤 정수 X에 대해서, X-X=0, X-0=X, (X\*2)-X=X 이다* 와 같은 대수적 표현을 최적화하는게 가장 간단한 예가 될 수 있다. 일단 첫번째로 패턴 매칭을 하기 위해 LLVM IR 에서 이런 대수적 표현이 어떻게 표현되는지를 알아야 한다. 이런 예가 가능하다. ::

   ...
   %example1 = sub i32 %a, %a
   ...
   %example2 = sub i32 %b, 0
   ...
   %tmp = mul i32 %c, 2
   %example3 = sub i32 %tmp, %c
   ...

  이런 류의 구멍난 변환에 대해서, LLVM은 다른 고수준 변환에서 유틸리티로 사용될만한 명령어 단순화 인터페이스를 제공한다. 이런 변환은 ``SimplifySubInt`` 함수에 있으며, 아래와 같은 모양을 하고 있다. ::

   // X - 0 -> X
   if (match(Op1, m_Zero())
     return Op0;

   // X - X-> 0
   if (Op0 == Op1)
     return Constant:getNullValue(Op0->getType());

   // (X*2) - X -> X
   if (match(Op0, m_Mul(m_Specific(Op1), m_ConstantInt<2>())))
     return Op1;

   ...

   return 0; // Nothing matched, return null to indicate no transformation

  이 코드에서 Op0, Op1 은 각각 왼쪽, 오른쪽의 정수 피연산자에 해당한다. LLVM은 C++로 구현되었는데, C++은 다른 언어(Objective Caml이라거나...)에 비해 패턴 매칭을 잘 지원하는 편은 아니다. 대신 아주 일반적인 템플릿 시스템을 가지고 있는데, 이것으로 어느정도 비슷한 일을 할 수 있다. ``match`` 함수와 ``m_*`` 함수가 LLVM IR 코드에 대해서 이런 선언적인 패턴매칭을 수행한다. 예를 들어서 위의 ``m_Specific`` 은 곱하기 연산의 왼쪽 피연산자가 Op1 인 경우에만 매치되는 술부(predicate)이다.

  동시에, 위 함수는 이 3가지 경우 모두 매치되어 코드 변환이 일어나는 경우 변환될 코드를 리턴한다. 변환이 없는 경우 - 그러니까 매치되지 않은 경우 - 에는 널포인터를 리턴한다. 이 함수를 호출한 쪽(``SimplifyInstruction``)은 명령어 코드를 보고 각 명령어에 맞는 함수를 호출해주는 일종의 분배기이다. 이 분배기를 사용한 드라이버 코드는 아래와 같은 모양이다. ::

   for (BasicBlock::iterator I=BB->begin(), E=BB->end(); I!=E; ++I) {
     if (Value *V=SimplifyInstruction(I))
       I->replaceAllUsesWith(V);
   }

  이 코드는 단순히 블럭의 각 명령어를 살펴보면서 단순화시킬 수 있는 것이 있는지 확인한다. 만약 있다면(``SimplifyInstruction``이 null이 아닌 것을 리턴) ``replaceAllUsesWith``를 호출해서 단순화된 코드로 업데이트를 수행한다.

4. LLVM's Implementation of Three-Phase Design

 LLVM 기반의 컴파일러에서, 프론트엔드는 입력 코드의 파싱, 검증 및 에러 진단 그리고 파싱된 코드를 LLVM IR로 변환하는 일을 책임진다. 가끔은 LLVM IR 이 아닌 AST 를 생성하고 이 AST를 다시 LLVM IR로 변환하기도 한다. 여튼 이 IR은 코드를 개선할 수 있는 분석/최적화 패스를 연속적으로 통과한 후에, 마지막으로 기계어로 변환하기 위한 코드 생성기로 전달된다. 이것은 아주 명확한 3단계 설계의 구현인데, 이는 LLVM IR로부터 이끌어낸 LLVM 설계의 유연성과 강력함에 기반한다.

 .. image:: http://www.aosabook.org/images/llvm/LLVMCompiler1.png

 - LLVM IR is a Complete Code Representation

  LLVM IR은 최적화 모듈의 잘 정의된, 그리고 유일한 인터페이스다. 따라서 LLVM을 위한 프론트엔드를 만들기 위해서 알아야 할 것은, LLVM IR이 무엇인지, 어떻게 동작하는지 그리고 필요한 불변값은 무엇인지가 전부라고 할 수 있다. LLVM IR은 일차적으로 텍스트 형식을 가지고 있기 때문에 프론트엔드가 출력하는 LLVM IR은 텍스트 형식으로 하는 것이 가능하다. 뿐만 아니라 이는 꽤 괜찮은 선택이기도 한데, 유닉스 파이프를 사용해서 *bit-code* 로 변환할 수 있고, 최적화 모듈이나 코드 생성기에 바로 넘길 수도 있기 때문이다.

  놀라울 수도 있지만, 바로 이 특징이 LLVM 성공의 주요 요인 중 하나이다. GCC 처럼 비교적 잘 설계된 컴파일러조차도 이런 특징을 지니지 못했다. GCC의 GIMPLE이라는 중간 단계 표현은 스스로 완결되지 않는다. 예를 들어 GCC 코드 생성기가 DWARF 디버깅 정보를 생성할 때 뒤로 돌아가서 소스레벨 트리를 살펴본다. GIMPLE 그 자체도 명령어에 대해서는 **tuple** 표현을 사용하지만, 피연산자는 아직도 소스 트리에 대한 레퍼런스로 들고 있다.

  이게 암시하는 바는, GCC의 프론트엔드 작성자는 GIMPLE외에 GCC의 트리 자료구조 역시 알아야 한다는 뜻이다. GCC의 백엔드 역시 비슷한 문제를 가지고 있다. 마지막으로, GCC는 "전체 코드를 나타내는 무언가" 를 덤프하지 못하고, GIMPLE(과 이에 연관된 다른 자료구조들)을 텍스트 형식으로 읽고 쓸 수 있는 방법이 없다. 그 결과로 GCC 로 뭔가 실험적인 작업을 하는 것은 매우 어려우며, 프론트엔드의 수가 쉽게 늘기 어렵다.

 - LLVM IR is a Collection of Libraries

  LLVM에서 LLVM IR의 설계 다음으로 중요한 것은, GCC같이 한 덩어리의 컴파일러 바이너리, 혹은 JVM/.NET같은 가상머신이 아니라 **라이브러리 집합**으로 설계되었다는 점이다. LLVM은 특정 문제를 위해 고안된 여러가지 유용한 컴파일러 기술의 묶음으로써, 기반구조를 형성하고 있다. 바로 이 점이 가장 강력한 특징 중 하나이지만, 가장 잘 놓치는 디자인 포인트이기도 하다.

  ... 오늘은 여기까지.


5. Design of the Retargetable LLVM Code Generator

 - LLVM Target Description Files

6. Interesting Capabilities Provided by a Modular Design

 - Choosing When and Where Each Phase Runs

 - Unit Testing the Optimizer

 - Automatic Test Case Reduction with BugPoint

7. Retrospective and Future Directions






* written in c++

Compiler design
    Three phase: Frontend -> Optimizer -> Backend
    What's the strength of three-phase design?
    Success stories:
        Java and .NET virtual machines
        Translate input source code into C
        GCC
    Why one more?

LLVM IR
    Ref: http://llvm.org/docs/LangRef.html
    LLVM IR is a low-level RISC-like virtual instructino set.
    Like most RISC instruction sets:
        * Support leniar sequence of simple instructions: add, sub, compare and branch
        * Three-address form
        * Support labels
    Unlike most RISC instruction sets:
        * Strongly typed with a simple type system
        * Some details of the machine are abstracted
        * Uses an infinite set of temporaries named with a % character
    Defined in three isomorphic form:
        * Textual (.ll)
        * In-memory structure
        * Bitcode (.bc)
        * llvm-as: .ll -> .bc
        * llvm-dis: .bc -> .ll
    Intermediate representation can be a 'perfect world' for the compiler optimizer
    Should be easy for a frontend to generate
    Should be expressive enough to allow important optimizations to be performed for real targets


Three-phase

    * Frontend: Parsing, validating and diagnosing erros. Then traslate parsed code into LLVM IR
    * Optimizer: Takes LLVM IR and write out LLVM IR.
    * Code generator: Convert LLVM IR into machine code
    Looks like pipelining, and it really is.


    * LLVM IR is complete code representation
    * LLVM is a collection of libraries

